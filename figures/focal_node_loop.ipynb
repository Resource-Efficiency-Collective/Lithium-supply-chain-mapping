{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86d2249b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add project root to Python path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T21:31:18.605046Z",
     "start_time": "2025-03-10T21:31:18.595500Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils.gcloud_utilities import *\n",
    "from utils.metadata import *\n",
    "from utils.preprocessing_utilities import (\n",
    "    import_operating_nodes,\n",
    "    expand_parameters_col_and_format,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83144ce45b926b78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T21:31:26.171294Z",
     "start_time": "2025-03-10T21:31:19.701650Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-10 16:28:58.932\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils.gcloud_utilities\u001b[0m:\u001b[36mfetch_gcs_bucket\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mFetching GCS bucket: lithium-datasets in project: critical-minerals'\u001b[0m\n",
      "c:\\Users\\bapti\\OneDrive - University of Cambridge\\Documents\\critical-minerals\\.venv\\Lib\\site-packages\\google\\auth\\_default.py:76: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. See the following page for troubleshooting: https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds. \n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "\u001b[32m2025-05-10 16:29:15.927\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils.gcloud_utilities\u001b[0m:\u001b[36mpull_from_gcs_csv\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mPulling data from preprocessed/benchmark/benchmark_nodes.csv in bucket lithium-datasets\u001b[0m\n",
      "\u001b[32m2025-05-10 16:29:17.467\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils.gcloud_utilities\u001b[0m:\u001b[36mpull_from_gcs_csv\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mPulling data from preprocessed/benchmark/endUse_nodes.csv in bucket lithium-datasets\u001b[0m\n",
      "\u001b[32m2025-05-10 16:29:17.657\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils.gcloud_utilities\u001b[0m:\u001b[36mpull_from_gcs_csv\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mPulling data from preprocessed/benchmark/edge_creation/benchmark_combined_edges.csv in bucket lithium-datasets\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "year = \"2023\"\n",
    "\n",
    "# Load data\n",
    "bucket, nodes = import_operating_nodes(year)\n",
    "endUse_nodes = pull_from_gcs_csv(\n",
    "    bucket, GCLOUD_PREPROCESSED_DIR + BENCHMARK_PREPROCESSED_DIR + \"endUse_nodes.csv\"\n",
    ")\n",
    "\n",
    "edges = pull_from_gcs_csv(\n",
    "    bucket,\n",
    "    GCLOUD_PREPROCESSED_DIR\n",
    "    + BENCHMARK_PREPROCESSED_DIR\n",
    "    + BENCHMARK_EDGES_DIR\n",
    "    + BENCHMARK_EDGES_FILE,\n",
    ")\n",
    "\n",
    "edges[\"properties\"] = edges[\"properties\"].astype(str).apply(ast.literal_eval)\n",
    "dict_df = pd.json_normalize(edges[\"properties\"])\n",
    "edges = edges.drop(columns=[\"properties\"]).join(dict_df)\n",
    "\n",
    "nodes_df = pd.concat((nodes, endUse_nodes))\n",
    "\n",
    "nodes_df[\"type\"] = (\n",
    "    nodes_df[\"mine_type\"]\n",
    "    .fillna(nodes_df[\"process_type\"])\n",
    "    .fillna(nodes_df[\"product_type\"])\n",
    ")\n",
    "nodes_df[\"country\"] = nodes_df[\"country\"].fillna(nodes_df[\"region\"])\n",
    "nodes_df[\"company\"] = nodes_df[\"company\"].fillna(nodes_df[\"operator_short_clean\"])\n",
    "# nodes_df = nodes_df.dropna(subset=['type'])[['node_id', 'type', year]]\n",
    "\n",
    "stages_dict = {\n",
    "    \"mining\": [\"Brine\", \"Spodumene\", \"Mica\", \"Pegmatite\"],\n",
    "    \"carbonate\": [\"Lithium Carbonate\"],\n",
    "    \"hydroxide\": [\"Lithium Hydroxide\"],\n",
    "    \"cathode\": [\n",
    "        \"NCM mid nickel\",\n",
    "        \"LFP\",\n",
    "        \"4V Ni or Mn based\",\n",
    "        \"NCA\",\n",
    "        \"NCM high nickel\",\n",
    "        \"LCO\",\n",
    "        \"NCM low nickel\",\n",
    "        \"5V Mn based\",\n",
    "    ],\n",
    "    \"battery\": [\n",
    "        \"Cylindrical\",\n",
    "        \"Pouch\",\n",
    "        \"Cylindrical, Pouch\",\n",
    "        \"Pouch, Prismatic\",\n",
    "        \"Prismatic\",\n",
    "        \"Cylindrical, Prismatic\",\n",
    "        \"Cylindrical, Pouch, Prismatic\",\n",
    "    ],\n",
    "    \"end_use\": [\"EV\", \"ESS\", \"Portable\"],\n",
    "}\n",
    "\n",
    "nodes_df[\"stage\"] = nodes_df[\"type\"].map(\n",
    "    {item: cat for cat, items in stages_dict.items() for item in items}\n",
    ")\n",
    "\n",
    "inputs = edges.merge(\n",
    "    nodes_df[[\"node_id\", \"type\", \"stage\", \"country\", \"company\"]],\n",
    "    left_on=[\"source\", \"edge_type\"],\n",
    "    right_on=[\"node_id\", \"type\"],\n",
    "    how=\"left\",\n",
    ")\n",
    "outputs = inputs[\n",
    "    [\n",
    "        \"stage\",\n",
    "        \"type\",\n",
    "        \"source\",\n",
    "        \"target\",\n",
    "        \"2023_volume\",\n",
    "        \"edge_type\",\n",
    "        \"edge_destination\",\n",
    "        \"country\",\n",
    "        \"company\",\n",
    "    ]\n",
    "].merge(\n",
    "    nodes_df[[\"node_id\", \"stage\", \"type\", \"country\", \"company\"]],\n",
    "    left_on=\"target\",\n",
    "    right_on=\"node_id\",\n",
    "    how=\"left\",\n",
    "    suffixes=(\"_source\", \"_target\"),\n",
    ")\n",
    "outputs = outputs[\n",
    "    (outputs[\"edge_destination\"].isna())\n",
    "    | (outputs[\"edge_destination\"] == outputs[\"type_target\"])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a997b16cb4a6e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T21:31:26.206565Z",
     "start_time": "2025-03-10T21:31:26.173742Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2. Keep only rows where stage_target matches next_stage_map[stage_source]\n",
    "stages = list(stages_dict.keys())\n",
    "next_stage_map = {stages[i]: stages[i + 1] for i in range(len(stages) - 1)}\n",
    "\n",
    "real_flows = pd.concat(\n",
    "    (\n",
    "        outputs[outputs[\"stage_source\"].map(next_stage_map) == outputs[\"stage_target\"]],\n",
    "        outputs[\n",
    "            (outputs[\"stage_source\"] == \"mining\")\n",
    "            & (outputs[\"stage_target\"] == \"hydroxide\")\n",
    "        ],\n",
    "        outputs[\n",
    "            (outputs[\"stage_source\"] == \"carbonate\")\n",
    "            & (outputs[\"stage_target\"] == \"cathode\")\n",
    "        ],\n",
    "    )\n",
    ")\n",
    "\n",
    "real_flows = real_flows[real_flows[\"source\"] != real_flows[\"target\"]]\n",
    "\n",
    "cathode_types = stages_dict[\"cathode\"]\n",
    "\n",
    "# Add node id prefix based on cathode type due to multiple cathode types from some facilities\n",
    "prefix_values = [str(i) for i in range(10, 56, 5)]  # Define prefix order\n",
    "prefix_map = dict(zip(cathode_types, prefix_values))  # Create mapping\n",
    "real_flows[\"source\"] = (\n",
    "    real_flows[\"type_source\"].map(prefix_map).fillna(\"\")\n",
    "    + real_flows[\"source\"].astype(str)\n",
    ").astype(int)\n",
    "\n",
    "real_flows[\"target\"] = (\n",
    "    real_flows[\"type_target\"].map(prefix_map).fillna(\"\")\n",
    "    + real_flows[\"target\"].astype(str)\n",
    ").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52372cad8d87055",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T21:31:26.224229Z",
     "start_time": "2025-03-10T21:31:26.222062Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_flow_fractions(G, target, vol_attr=\"vol\"):\n",
    "    \"\"\"\n",
    "    Computes the fraction of flow at each node that eventually reaches `target`.\n",
    "    Assumes the graph is a DAG.\n",
    "    \"\"\"\n",
    "    # Initialize all fractions to zero; set target's fraction to 1.\n",
    "    fractions = {node: 0 for node in G.nodes()}\n",
    "    fractions[target] = 1.0\n",
    "\n",
    "    try:\n",
    "        # Get a topological ordering (requires a DAG)\n",
    "        topo_order = list(nx.topological_sort(G))\n",
    "    except nx.NetworkXUnfeasible:\n",
    "        raise ValueError(\"The graph contains cycles. This method assumes a DAG.\")\n",
    "\n",
    "    # Process nodes in reverse topological order (from target upstream)\n",
    "    topo_order.reverse()\n",
    "    for node in topo_order:\n",
    "        # For every predecessor of the current node,\n",
    "        # add the contribution from the edge from pred -> node.\n",
    "        for pred in G.predecessors(node):\n",
    "            # Sum of volumes on all edges leaving 'pred'\n",
    "            out_edges = list(G.out_edges(pred, data=True))\n",
    "            total_out = sum(edge_data[vol_attr] for _, _, edge_data in out_edges)\n",
    "            if total_out > 0:\n",
    "                # The fraction of pred's flow that goes to this child\n",
    "                flow_ratio = G[pred][node][vol_attr] / total_out\n",
    "                fractions[pred] += fractions[node] * flow_ratio\n",
    "    return fractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c4731f333453c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T21:31:26.273164Z",
     "start_time": "2025-03-10T21:31:26.238972Z"
    }
   },
   "outputs": [],
   "source": [
    "# Build a directed graph from the DataFrame\n",
    "G = nx.from_pandas_edgelist(\n",
    "    real_flows,\n",
    "    source=\"source\",\n",
    "    target=\"target\",\n",
    "    edge_attr=year + \"_volume\",\n",
    "    create_using=nx.DiGraph(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced6a43467db3e40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T21:34:34.931568Z",
     "start_time": "2025-03-10T21:31:33.090052Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 247/247 [10:26<00:00,  2.53s/it]\n"
     ]
    }
   ],
   "source": [
    "all_trees = pd.DataFrame()\n",
    "\n",
    "battery_node_ids = nodes_df[\n",
    "    [i in list(stages_dict[\"battery\"]) for i in nodes_df[\"type\"]]\n",
    "][\"node_id\"].unique()\n",
    "\n",
    "for battery_node_id in tqdm(battery_node_ids):\n",
    "\n",
    "    # Compute flow fractions for each node\n",
    "    fractions = compute_flow_fractions(G, battery_node_id, vol_attr=year + \"_volume\")\n",
    "\n",
    "    # Now, adjust each edge's volume to only account for the portion that eventually reaches final_target.\n",
    "    # For an edge (i -> j), the adjusted volume is: vol(i->j) * fraction[j]\n",
    "    adjusted_flows = real_flows.copy()\n",
    "    adjusted_flows[\"adj_vol\"] = adjusted_flows.apply(\n",
    "        lambda row: row[year + \"_volume\"] * fractions.get(row[\"target\"], 0), axis=1\n",
    "    )\n",
    "\n",
    "    upstream_tree = adjusted_flows[adjusted_flows[\"adj_vol\"] > 0].copy()\n",
    "\n",
    "    upstream_tree[\"battery_node_id\"] = battery_node_id\n",
    "\n",
    "    all_trees = pd.concat((all_trees, upstream_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bf835c2c90e2d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T21:39:05.911829Z",
     "start_time": "2025-03-10T21:39:01.408464Z"
    }
   },
   "outputs": [],
   "source": [
    "all_trees.to_csv(project_root + \"/figures/main_results/upstream_trees.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42427bbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
